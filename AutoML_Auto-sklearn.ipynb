{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc556833",
   "metadata": {},
   "source": [
    "# Auto-sklearn practical approach\n",
    "## The following code can be used in an Jupyter Notebook (Python 3.8.X, Auto-sklearn 0.14.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2eaa2",
   "metadata": {},
   "source": [
    "Import Python modules and prepare the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db6692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "import autosklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365b1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'MOVIESTREAM_CHURN_RED_TRAIN.csv'\n",
    "dataframe = read_csv(filename)\n",
    "dataframe['YRS_CURRENT_EMPLOYER'] = dataframe['YRS_CURRENT_EMPLOYER'].fillna(0)\n",
    "array = dataframe.values\n",
    "ID_train = array[:,0]\n",
    "X_train = array[:,1:-1]\n",
    "y_train = array[:,-1]\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = LabelEncoder().fit_transform(y_train.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412a481",
   "metadata": {},
   "source": [
    "__Build a Classification model__. A time budget of five minutes has been set. The _n_jobs_ parameter establishes the number of jobs to run in parallel. The _per_run_time_limit_ value must be high enough so that a typical machine learning algorithm can be fit on the training data without exceeding this time limit. _Metric_ parameter represents the evaluation metric to evaluate the model performance. For classification, the possible values are: _roc_auc_, _precision_, _accuracy_, _balanced_accuracy_, _f1_, _f1_micro_, _f1_marco_, _f1_weighted_, _f1_samples_, _recall_, _recall_micro_, _recall_macro_, _recall_samples_, _recall_weighted_, _precision_macro_, _precision_micro_, _precision_samples_, _precision_weighted_, _log_loss_ and _average_percision_. \n",
    "_Fit_ both optimizes the machine learning models and builds an ensemble out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ccc48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoSklearnClassifier(time_left_for_this_task=300, per_run_time_limit=60, n_jobs=2, metric=autosklearn.metrics.accuracy, ensemble_size=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab462be8",
   "metadata": {},
   "source": [
    "__Analysis and inspection of the model__. The _PipelineProfiler_ package is a very useful tool for interactive analysis and inspection of the classification model; the steps and algorithms used for its construction are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8c02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PipelineProfiler\n",
    "profiler_data = PipelineProfiler.import_autosklearn(model)\n",
    "PipelineProfiler.plot_pipeline_matrix(profiler_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400aad65",
   "metadata": {},
   "source": [
    "__Save optimized model to a file__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be397d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'auto_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc62cee",
   "metadata": {},
   "source": [
    "__Restore tuned model from the file__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40159bc7",
   "metadata": {},
   "source": [
    "Prepare the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21269d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'MOVIESTREAM_CHURN_RED_TEST.csv'\n",
    "dataframe = read_csv(filename)\n",
    "dataframe['YRS_CURRENT_EMPLOYER'] = dataframe['YRS_CURRENT_EMPLOYER'].fillna(0)\n",
    "array = dataframe.values\n",
    "ID_test = array[:,0]\n",
    "X_test = array[:,1:-1]\n",
    "y_test = array[:,-1]\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = LabelEncoder().fit_transform(y_test.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bf186",
   "metadata": {},
   "source": [
    "__Score the machine learning model__: the predicted values and the probability estimates for each value are obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "probs = loaded_model.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
